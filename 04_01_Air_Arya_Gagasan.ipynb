{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryagagas/machine-learning-and-deep-learning-assignment/blob/main/04_01_Air_Arya_Gagasan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrq5s9WWYcAV"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOGAR9QHYcAZ"
      },
      "source": [
        "Preparation biasa dilakukan untuk mempersiapkan data sebelum masuk dalam tahap pemodelan. <br>\n",
        "Berikut adalah tahapan yang akan dilalui pada data `SC_HW1_bank_data.csv` sebelum tahap pemodelan :\n",
        "1. Import Library\n",
        "2. Input Dataset\n",
        "3. Preprocessing\n",
        "4. Train-Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUIg363RYcAZ"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWrO8BImYcAa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_wYppbCYcAb"
      },
      "source": [
        "## Input Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU29IupsYcAb"
      },
      "outputs": [],
      "source": [
        "#Membaca data dan memasukkannya ke dalam bentuk Pandas Dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Rietaros/kampus_merdeka/main/SC_HW1_bank_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7swrXGTYcAc",
        "outputId": "7b14e0d7-dc2d-4355-b3da-0881f069c6f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Geography', 'Gender', 'Age', 'Tenure',\n",
              "       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
              "       'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Jalankan code untuk mengecek nama kolom yang tersedia\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySBcdpGy4rb3"
      },
      "outputs": [],
      "source": [
        "#Hilangkan kolom yang dirasa tidak relevan dengan model (contoh: ID). None dapat diisi dengan nama-nama kolom yang akan digunakan.\n",
        "#Contoh df = df[['X1','X2', 'Y']].copy()\n",
        "\n",
        "#START CODE\n",
        "df = df[['Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAUrcQVIYcAe"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owVHMXqEYcAe"
      },
      "outputs": [],
      "source": [
        "#Lakukan One-Hot Encoder untuk data categorical, dengan fungsi pandas get_dummies\n",
        "\n",
        "#START CODE\n",
        "df = pd.get_dummies(df, columns=['Geography', 'Gender'], prefix=['Geo', 'Gen'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMNWzfUbYcAf"
      },
      "outputs": [],
      "source": [
        "#Pisahkan mana X (feature) dengan Y,\n",
        "#Y adalah kolom \"Exited\"\n",
        "\n",
        "#START CODE\n",
        "X = df.drop('Exited', axis=1)\n",
        "y = df.loc[:, 'Exited']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWfdSiCxYcAg"
      },
      "outputs": [],
      "source": [
        "#Lakukan Scaler dan/atau Noermalisasi jika diperlukan\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#START CODE\n",
        "scaler = MinMaxScaler()\n",
        "X_transform = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5u5pH3uYcAg"
      },
      "outputs": [],
      "source": [
        "#Ini digunakan jika dilakukan scaler/Normalisas. Jika tidak, code ini bisa dilewat dan diganti dengan code yang ada di dalam komen\n",
        "X_transform = pd.DataFrame(X_transform, columns = X.columns)\n",
        "#X_transform = X.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pi0qKQAYcAh"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RDnybGDYcAh"
      },
      "outputs": [],
      "source": [
        "#Split menjadi train dan test dengan test_size 25%\n",
        "#Tidak perlu mengubah code ini\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_transform,y,test_size = 0.25,random_state = 123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hIL9sbPYcAh"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PPYhjm3YcAi"
      },
      "source": [
        "## Model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt2iNWWTYcAj"
      },
      "source": [
        "### Soal :\n",
        "Jelaskan secara Singkat Model pertama yang digunakan!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> KNN bekerja dengan cara mencari sejumlah K tetangga terdekat dari suatu data uji (data yang akan diprediksi) dalam ruang fitur berdasarkan jarak euclidean atau metrik lainnya. Kemudian, berdasarkan mayoritas kelas dari tetangga-tetangga tersebut, data uji akan diklasifikasikan ke dalam kelas yang paling mendominasi di antara tetangga-tetangga tersebut.\n",
        "\n"
      ],
      "metadata": {
        "id": "cQ3gZR-JwGZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pilih salah satu metode Machine Leaarning\n",
        "#Model Machine Learning dapat dipanggil terlebih dahulu melalui library yang digunakan. Gunakan library scikit learn seperti pada contoh\n",
        "\n",
        "#Contoh pemanggilan library dan penggunaannya dalam model\n",
        "\n",
        "# model1 = LogisticRegression()\n",
        "# params = { \"tol\": [0.1,0.01,0.001], 'C':[0.5,1.0,1.5,2.0]}\n",
        "\n",
        "\n",
        "#START CODE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model1 = KNeighborsClassifier()\n",
        "\n",
        "# Definisi hyperparameter yang akan dituning\n",
        "params = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "#END CODE\n",
        "\n",
        "#Lakukan parameter tuning sesuai hyperparameter yang dibutuhkan\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "             estimator= model1,\n",
        "             param_grid= params,\n",
        "             scoring = 'accuracy',\n",
        "             n_jobs = 10, # core cpu yang digunakan\n",
        "             cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)\n",
        "            )\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "grid.best_params_"
      ],
      "metadata": {
        "id": "bnqFXuCyYcAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a7f5a6-fc9a-4e92-a2ea-7603176202d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f32JE8kYcAk",
        "outputId": "22bc11fb-dd0b-48cb-e672-2af749d630d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90      1983\n",
            "           1       0.67      0.33      0.45       517\n",
            "\n",
            "    accuracy                           0.83      2500\n",
            "   macro avg       0.76      0.65      0.67      2500\n",
            "weighted avg       0.81      0.83      0.80      2500\n",
            "\n",
            "\n",
            "[[1897   86]\n",
            " [ 344  173]]\n",
            "\n",
            "0.828\n"
          ]
        }
      ],
      "source": [
        "#lakukan evaluasi dengan beberapa maetric di bawah ini\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXuooROd4rb8"
      },
      "source": [
        "## Model2\n",
        "### Soal :\n",
        "Jelaskan secara Singkat Model ke-2 yang digunakan!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Random Forest bekerja dengan cara membangun sejumlah pohon keputusan acak (forest) berdasarkan subset data pelatihan yang dipilih secara acak dan kemudian menggabungkan hasil prediksi dari masing-masing pohon untuk menghasilkan hasil akhir. Hal ini membantu mengurangi overfitting yang mungkin terjadi dalam model pohon keputusan tunggal."
      ],
      "metadata": {
        "id": "IH3m8ULow3sI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfJRofJL4rb8",
        "outputId": "ccbc9e94-0ce8-47ab-a791-acd46dbb79a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 10,\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Pilih salah satu metode Machine Leaarning\n",
        "#Model Machine Learning dapat dipanggil terlebih dahulu melalui library yang digunakan. Gunakan library scikit learn seperti pada contoh\n",
        "\n",
        "#Contoh pemanggilan library dan penggunaannya dalam model\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#model1 = LogisticRegression()\n",
        "#params = { \"tol\": [0.1,0.01,0.001], 'C':[0.5,1.0,1.5,2.0]}\n",
        "\n",
        "\n",
        "#START CODE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Tentukan model\n",
        "model2 = RandomForestClassifier()\n",
        "\n",
        "# Tentukan daftar hyperparameter yang akan diuji\n",
        "params = {\n",
        "    'n_estimators': [100, 200, 300],  # Jumlah pohon keputusan dalam ensemble\n",
        "    'max_depth': [None, 10, 20],  # Kedalaman maksimum setiap pohon\n",
        "    'min_samples_split': [2, 5, 10],  # Jumlah sampel minimum yang diperlukan untuk membagi node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Jumlah sampel minimum yang diperlukan untuk menjadi leaf node\n",
        "}\n",
        "#END CODE\n",
        "\n",
        "#Lakukan parameter tuning sesuai hyperparameter yang dibutuhkan\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "             estimator= model2,\n",
        "             param_grid= params,\n",
        "             scoring = 'accuracy',\n",
        "             n_jobs = 10, # core cpu yang digunakan\n",
        "             cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)\n",
        "            )\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOZ6oeyW4rb9",
        "outputId": "52720715-030c-4a1d-d74f-ea13d96c65df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92      1983\n",
            "           1       0.79      0.44      0.57       517\n",
            "\n",
            "    accuracy                           0.86      2500\n",
            "   macro avg       0.83      0.71      0.74      2500\n",
            "weighted avg       0.85      0.86      0.84      2500\n",
            "\n",
            "\n",
            "[[1923   60]\n",
            " [ 288  229]]\n",
            "\n",
            "0.8608\n"
          ]
        }
      ],
      "source": [
        "#lakukan evaluasi\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poj5B7fF4rb9"
      },
      "source": [
        "## Model3\n",
        "### Soal :\n",
        "Jelaskan secara Singkat Model ke-3 yang digunakan!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Pada dasarnya, Gradient Boosting bekerja dengan cara menggabungkan sejumlah model lemah (dalam hal ini, pohon keputusan) menjadi model yang kuat. Setiap pohon yang ditambahkan ke ensemble fokus pada kesalahan prediksi yang dibuat oleh pohon-pohon sebelumnya. Dengan cara ini, model secara bertahap \"mempelajari\" data dengan mengurangi kesalahan prediksi."
      ],
      "metadata": {
        "id": "sqh0x1g2xCAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6riqEA74rb9",
        "outputId": "52376e0e-b504-465c-dc1c-73f9a3590629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#Pilih salah satu metode Machine Leaarning\n",
        "#Model Machine Learning dapat dipanggil terlebih dahulu melalui library yang digunakan. Gunakan library scikit learn seperti pada contoh\n",
        "\n",
        "#Contoh pemanggilan library dan penggunaannya dalam model\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#model1 = LogisticRegression()\n",
        "#params = { \"tol\": [0.1,0.01,0.001], 'C':[0.5,1.0,1.5,2.0]}\n",
        "\n",
        "\n",
        "#START CODE\n",
        "# Import library yang dibutuhkan\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Tentukan model Gradient Boosting\n",
        "model3 = GradientBoostingClassifier()\n",
        "\n",
        "# Tentukan daftar hyperparameter yang akan diuji\n",
        "params = {\n",
        "    'n_estimators': [50, 100, 200],  # Jumlah estimator (pohon) dalam ensemble\n",
        "    'learning_rate': [0.01, 0.1, 0.2],  # Tingkat pembelajaran\n",
        "    'max_depth': [3, 4, 5]  # Kedalaman maksimum pohon\n",
        "}\n",
        "#END CODE\n",
        "\n",
        "#Lakukan parameter tuning sesuai hyperparameter yang dibutuhkan\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "             estimator= model3,\n",
        "             param_grid= params,\n",
        "             scoring = 'accuracy',\n",
        "             n_jobs = 10, # core cpu yang digunakan\n",
        "             cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)\n",
        "            )\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D60gsBj4rb9",
        "outputId": "34349aeb-b96c-4e79-8712-88bfcc594a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      1983\n",
            "           1       0.78      0.51      0.62       517\n",
            "\n",
            "    accuracy                           0.87      2500\n",
            "   macro avg       0.83      0.74      0.77      2500\n",
            "weighted avg       0.86      0.87      0.86      2500\n",
            "\n",
            "\n",
            "[[1906   77]\n",
            " [ 251  266]]\n",
            "\n",
            "0.8688\n"
          ]
        }
      ],
      "source": [
        "#lakukan evaluasi\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blfl1F2M4rb-"
      },
      "source": [
        "## Tarik Kesimpulan Model Mana yang terbaik beserta alasannya"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil evaluasi, Model 3 (Gradient Boosting Classifier) adalah model terbaik untuk tugas ini. Ini dapat dijelaskan sebagai berikut:\n",
        "\n",
        "**Model 1 (K-Nearest Neighbors):**\n",
        "\n",
        "> Parameter Terbaik:\n",
        "\n",
        "```\n",
        "{'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
        "```\n",
        "\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.85      0.96      0.90      1983\n",
        "           1       0.67      0.33      0.45       517\n",
        "\n",
        "    accuracy                           0.83      2500\n",
        "   macro avg       0.76      0.65      0.67      2500\n",
        "weighted avg       0.81      0.83      0.80      2500\n",
        "\n",
        "\n",
        "[[1897   86]\n",
        " [ 344  173]]\n",
        "\n",
        "0.828\n",
        "```\n",
        "\n",
        "**Model 2 (Random Forest Classifier):**\n",
        "\n",
        "> Parameter Terbaik:\n",
        "\n",
        "```\n",
        "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
        "```\n",
        "\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.87      0.97      0.92      1983\n",
        "           1       0.79      0.44      0.57       517\n",
        "\n",
        "    accuracy                           0.86      2500\n",
        "   macro avg       0.83      0.71      0.74      2500\n",
        "weighted avg       0.85      0.86      0.84      2500\n",
        "\n",
        "\n",
        "[[1923   60]\n",
        " [ 288  229]]\n",
        "\n",
        "0.8608\n",
        "```\n",
        "\n",
        "**Model 3 (Gradient Boosting Classifier):**\n",
        "\n",
        "> Parameter Terbaik:\n",
        "\n",
        "```\n",
        "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
        "```\n",
        "\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.88      0.96      0.92      1983\n",
        "           1       0.78      0.51      0.62       517\n",
        "\n",
        "    accuracy                           0.87      2500\n",
        "   macro avg       0.83      0.74      0.77      2500\n",
        "weighted avg       0.86      0.87      0.86      2500\n",
        "\n",
        "\n",
        "[[1906   77]\n",
        " [ 251  266]]\n",
        "\n",
        "0.8688\n",
        "```\n",
        "\n",
        "**Kesimpulan:** <br>\n",
        "> Model 3 **(Gradient Boosting Classifier)** adalah yang terbaik karena memiliki akurasi tertinggi (0.8688) atau ketika dibulatkan menjadi **87%** dan F1-score tertinggi untuk Kelas 1 (0.62). Meskipun Model 2 **(Random Forest Classifier)** memiliki akurasi yang baik, Model 3 memiliki presisi dan recall yang lebih baik untuk kelas 1, sehingga lebih cocok untuk tugas ini. Model 1 **(K-Nearest Neighbors)** memiliki kinerja yang lebih rendah dibandingkan dengan Model 2 dan Model 3.\n",
        "\n",
        "> Model 3 adalah pilihan terbaik karena mampu menghasilkan prediksi yang baik dengan keseimbangan antara presisi dan recall, yang penting dalam pemodelan klasifikasi. Model ini juga memiliki parameter terbaik yang telah di-tune untuk mencapai kinerja maksimal."
      ],
      "metadata": {
        "id": "m55MOvyr0iBl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc-autonumbering": true,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}